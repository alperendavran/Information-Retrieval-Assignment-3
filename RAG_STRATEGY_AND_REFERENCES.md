# ğŸ“š RAG Sistemi Strateji ve Referans Belgesi

## Ä°Ã§indekiler
1. [Anahtar Kavramlar](#anahtar-kavramlar)
2. [Ã–nerilen Stratejiler](#Ã¶nerilen-stratejiler)
3. [Deney PlanÄ±](#deney-planÄ±)
4. [DeÄŸerlendirme Metodolojisi](#deÄŸerlendirme-metodolojisi)
5. [Akademik Referanslar](#akademik-referanslar)

---

## ğŸ”‘ Anahtar Kavramlar

### RAG ParadigmalarÄ± (Kaynak: Ders SlaytÄ± + RAG-overview.pdf)

| Paradigma | Ã–zellikler | GÃ¼Ã§lÃ¼ Yanlar |
|-----------|-----------|--------------|
| **Naive RAG** | Keyword-based retrieval (TF-IDF, BM25), statik dataset | Basit, uygulamasÄ± kolay |
| **Advanced RAG** | Dense retrieval (DPR), neural ranking, multi-hop retrieval | YÃ¼ksek precision, contextual relevance |
| **Modular RAG** | Hybrid retrieval, tool integration, composable pipelines | YÃ¼ksek esneklik, Ã¶lÃ§eklenebilir |
| **Graph RAG** | Knowledge graph entegrasyonu, community detection | Relational reasoning, global sensemaking |
| **Agentic RAG** | Autonomous agents, iterative refinement | Dinamik adaptasyon, multi-domain |

### RAG Temel BileÅŸenleri (Lewis et al., 2020)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG PIPELINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. CHUNKING     â†’  2. EMBEDDING  â†’  3. INDEXING               â”‚
â”‚       â†“                  â†“               â†“                      â”‚
â”‚  4. RETRIEVAL   â†’  5. AUGMENTATION â†’ 6. GENERATION             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Ã–nerilen Stratejiler

### 1. Document Chunking Stratejileri (%10)

#### Strateji A: Fixed-Size Chunking with Overlap
```python
CHUNK_SIZE = 200-300  # tokens (Ã¶nerilen aralÄ±k)
OVERLAP = 0.1-0.2     # %10-20 overlap
```
**Referans:** "Practical guidelines: Chunk size 200â€“300 tokens, Overlap 10â€“20%" (Ders SlaytÄ±)

#### Strateji B: Semantic Chunking
- CÃ¼mle sÄ±nÄ±rlarÄ±nda bÃ¶lme
- Paragraf bazlÄ± bÃ¶lme (doÄŸal breakpoint'ler varsa)
- Markdown/HTML yapÄ±sÄ±na gÃ¶re bÃ¶lme

**Kaynak:** "Keep semantic coherence: don't split mid-sentence or mid-section" (Ders SlaytÄ±)

#### Strateji C: LLM-based Fact Extraction (Advanced)
```python
# GPT-4 ile bilgi yoÄŸunluÄŸunu artÄ±rma
# Raw HTML: ~55,000 tokens â†’ GPT-4 processed: 330 tokens
```
**Referans:** 15_Advanced_RAG_Techniques.pdf, Technique 1

### 2. Embedding & Indexing Stratejileri (%20)

#### Ã–nerilen Embedding Modelleri (Yerel Ã‡alÄ±ÅŸabilir)

| Model | Boyut | Avantaj | KullanÄ±m |
|-------|-------|---------|----------|
| `sentence-transformers/all-MiniLM-L6-v2` | 384d | HÄ±zlÄ±, hafif | KÃ¼Ã§Ã¼k dataset |
| `sentence-transformers/all-mpnet-base-v2` | 768d | Daha doÄŸru | Orta dataset |
| `BAAI/bge-small-en-v1.5` | 384d | SOTA performans | Genel kullanÄ±m |
| `intfloat/e5-small-v2` | 384d | Ã‡ok dilli destek | TÃ¼rkÃ§e iÃ§erik |

#### Indexing YaklaÅŸÄ±mlarÄ±

**Option 1: FAISS (Ã–nerilen)**
```python
import faiss
index = faiss.IndexFlatIP(embedding_dim)  # Cosine similarity iÃ§in normalize edilmiÅŸ vektÃ¶rler
# veya
index = faiss.IndexIVFFlat(quantizer, embedding_dim, nlist)  # BÃ¼yÃ¼k datasetler iÃ§in
```

**Option 2: Scikit-learn**
```python
from sklearn.metrics.pairwise import cosine_similarity
```

**Referans:** "Build a similarity index (e.g., cosine similarity, FAISS, or sklearn)" (Assignment)

### 3. Retrieval Module Stratejileri (%20)

#### Dense Passage Retrieval (DPR)
```
query q â†’ BERTq â†’ embq
                        â†˜
                         cosine_similarity â†’ Top-k
                        â†—
document d â†’ BERTd â†’ embd
```
**Referans:** Karpukhin et al. (2020), Lewis et al. (2020)

#### Optimal k DeÄŸeri
- **k=3-5:** KÃ¼Ã§Ã¼k dataset iÃ§in Ã¶nerilen (assignment dataseti)
- **k=1:** Ã‡ok kÃ¼Ã§Ã¼k, yetersiz context
- **k=20:** Muhtemelen Ã§ok bÃ¼yÃ¼k, noise ekler

#### Hybrid Retrieval (Advanced)
```python
# BM25 + Dense retrieval kombinasyonu
final_score = Î± * bm25_score + (1-Î±) * dense_score
```
**Referans:** Modular RAG - "Hybrid retrieval strategies combining sparse and dense" (RAG-overview.pdf)

### 4. Answer Generation Stratejileri (%30)

#### Prompt Template
```python
SYSTEM_PROMPT = """You are a helpful assistant for the University of Antwerp 
Computer Science Masters program. Answer questions based ONLY on the provided 
context. If the context doesn't contain the answer, say "I don't have enough 
information to answer this question."

Context:
{retrieved_passages}

Question: {user_query}

Answer:"""
```

#### Few-shot Learning (Opsiyonel)
```python
# 2-3 Ã¶rnek eklemek performansÄ± artÄ±rabilir
examples = [
    {"question": "...", "answer": "..."},
    {"question": "...", "answer": "..."}
]
```

**Referans:** "Use frozen LLMs (GPT-4, etc.) with zero-shot/few-shot learning" (Ders SlaytÄ±)

### 5. Evaluation Stratejileri (%20)

#### 5.1 Retrieval Quality Metrics

**Recall@k:**
```python
def recall_at_k(retrieved_docs, relevant_docs, k):
    retrieved_set = set(retrieved_docs[:k])
    relevant_set = set(relevant_docs)
    return len(retrieved_set & relevant_set) / len(relevant_set)
```

**Mean Reciprocal Rank (MRR):**
```python
def mrr(retrieved_docs, relevant_doc):
    for i, doc in enumerate(retrieved_docs):
        if doc == relevant_doc:
            return 1 / (i + 1)
    return 0
```

#### 5.2 Answer Quality - LLM as a Judge

**RAGAS Framework (Referans: Es et al., 2024):**
- **Faithfulness:** Cevap context'e sadÄ±k mÄ±?
- **Answer Relevance:** Cevap soruyla alakalÄ± mÄ±?
- **Context Relevance:** Getirilen context alakalÄ± mÄ±?

**Comprehensiveness & Diversity (GraphRAG kriterleri):**
```python
judge_prompt = """Compare the following two answers:
Answer A: {answer_with_rag}
Answer B: {answer_without_rag}

Evaluate on:
1. Comprehensiveness (0-100): How detailed and complete?
2. Correctness (0-100): Is the information accurate?
3. Hallucination (0-100): Does it contain made-up facts?
"""
```
**Referans:** Edge et al. (2024), Zheng et al. (2024) - LLM-as-a-judge

#### 5.3 Error Analysis Checklist

| Hata Tipi | Ã–rnek Senaryo | OlasÄ± Sebep |
|-----------|---------------|-------------|
| **Retrieval Failure** | AlakasÄ±z dokÃ¼manlar getirildi | Embedding model uyumsuzluÄŸu |
| **Context Missing** | DoÄŸru bilgi chunk'lanÄ±rken kayboldu | Chunk size Ã§ok kÃ¼Ã§Ã¼k |
| **Hallucination** | YanlÄ±ÅŸ bilgi Ã¼retildi | Context yetersiz / prompt zayÄ±f |
| **Incomplete Answer** | KÄ±smi cevap | k deÄŸeri dÃ¼ÅŸÃ¼k |

---

## ğŸ§ª Deney PlanÄ±

### Deney 1: Chunk Size Optimization
```
DeÄŸiÅŸken: chunk_size = [100, 200, 300, 500] tokens
Sabit: overlap=0.1, embedding=all-MiniLM-L6-v2, k=5
Metrik: Recall@5, Answer Quality
```

### Deney 2: Embedding Model Comparison
```
DeÄŸiÅŸken: model = [MiniLM, MPNet, BGE-small, E5-small]
Sabit: chunk_size=200, overlap=0.1, k=5
Metrik: Recall@5, Retrieval Latency
```

### Deney 3: Top-k Optimization
```
DeÄŸiÅŸken: k = [1, 3, 5, 7, 10]
Sabit: chunk_size=200, embedding=MiniLM
Metrik: Answer Quality, Token Usage
```

### Deney 4: RAG vs No-RAG Baseline
```
Condition A: GPT-4o with retrieved context
Condition B: GPT-4o without context (baseline)
Metrik: Correctness, Hallucination Rate
```

### Deney 5: Overlap Ratio Effect
```
DeÄŸiÅŸken: overlap = [0, 0.1, 0.2, 0.3]
Sabit: chunk_size=200
Metrik: Context Coverage, Retrieval Quality
```

---

## ğŸ“Š DeÄŸerlendirme Metodolojisi

### Test Soru Seti OluÅŸturma

**AdÄ±m 1: Manual Question Generation**
- Dataset'ten 20-30 test sorusu oluÅŸtur
- Ground truth cevaplarÄ± belirle
- Soru kategorileri: Factual, Comparative, Complex

**AdÄ±m 2: LLM-Generated Questions (GraphRAG yaklaÅŸÄ±mÄ±)**
```python
prompt = """Based on this document about the CS Masters program, 
generate 5 questions that would require understanding the content:
{document}
"""
```

### Evaluation Pipeline

```
1. Test Query â†’ 2. Retrieval â†’ 3. Generation â†’ 4. Evaluation
      â†“              â†“              â†“              â†“
   20-30 Q's    Recall@k      GPT-4o Answer   LLM-as-Judge
                                              + Manual Review
```

---

## ğŸ“– Akademik Referanslar

### Temel RAG Makaleleri

1. **Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020).** 
   Retrieval-augmented generation for knowledge-intensive NLP tasks. 
   *Advances in Neural Information Processing Systems, 33*, 9459-9474.
   - **KullanÄ±m:** End-to-end RAG architecture, RAG-Sequence vs RAG-Token

2. **Karpukhin, V., OÄŸuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., ... & Yih, W. T. (2020).**
   Dense passage retrieval for open-domain question answering. 
   *EMNLP 2020*.
   - **KullanÄ±m:** Dense Passage Retrieval (DPR), bi-encoder architecture

3. **Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., ... & Wang, H. (2024).**
   Retrieval-Augmented Generation for Large Language Models: A Survey.
   *arXiv preprint arXiv:2312.10997*.
   - **KullanÄ±m:** RAG paradigmalarÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rmasÄ± (Naive, Advanced, Modular)

### Ä°leri RAG Teknikleri

4. **Edge, D., Trinh, H., Cheng, N., Bradley, J., Chao, A., Mody, A., ... & Larson, J. (2024).**
   From Local to Global: A GraphRAG Approach to Query-Focused Summarization.
   *arXiv preprint arXiv:2404.16130*.
   - **KullanÄ±m:** Knowledge graph + community detection, global sensemaking

5. **Singh, A., Ehtesham, A., Kumar, S., & Khoei, T. T. (2025).**
   Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG.
   *arXiv preprint arXiv:2501.09136*.
   - **KullanÄ±m:** Agentic patterns (reflection, planning, tool use)

6. **15 Advanced RAG Techniques (2024).**
   From pre-retrieval to generation. [White Paper]
   - **KullanÄ±m:** Hierarchical indexing, hypothetical question index, chunking strategies

### DeÄŸerlendirme MetodlarÄ±

7. **Es, S., James, J., Espinosa-Anke, L., & Schockaert, S. (2024).**
   RAGAS: Automated Evaluation of Retrieval Augmented Generation.
   *Proceedings of the 18th EACL: System Demonstrations*.
   - **KullanÄ±m:** Faithfulness, Answer Relevance, Context Relevance metrikleri

8. **Zheng, L., Chiang, W. L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., ... & Xing, E. P. (2024).**
   Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.
   *NeurIPS 2023*.
   - **KullanÄ±m:** LLM-as-a-judge paradigmasÄ±

### Ders KaynaklarÄ±

9. **Calders, T. (2025-2026).**
   Retrieval Augmented Generation [Lecture Slides].
   University of Antwerp, Information Retrieval Course.
   - **KullanÄ±m:** RAG components, chunking guidelines, evaluation

10. **Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020).**
    Language models are few-shot learners.
    *Advances in Neural Information Processing Systems, 33*, 1877-1901.
    - **KullanÄ±m:** Few-shot/zero-shot learning, frozen LLM kullanÄ±mÄ±

11. **Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., ... & Lowe, R. (2022).**
    Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems, 35*, 27730-27744.
    - **KullanÄ±m:** Fine-tuning LLMs, instruction following

---

## ğŸ› ï¸ Ã–nerilen Teknoloji Stack

### Python KÃ¼tÃ¼phaneleri

```python
# Core
sentence-transformers>=2.2.0  # Embedding models
faiss-cpu>=1.7.4             # Vector indexing
openai>=1.0.0                # GPT-4o API

# YardÄ±mcÄ±
tiktoken>=0.5.0              # Token counting
numpy>=1.24.0                # Numerical operations
pandas>=2.0.0                # Data handling
scikit-learn>=1.3.0          # Cosine similarity, metrics

# Opsiyonel
langchain>=0.1.0             # RAG framework (opsiyonel)
chromadb>=0.4.0              # Vector database alternative
```

### Proje YapÄ±sÄ± Ã–nerisi

```
rag-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Orijinal veriler
â”‚   â”œâ”€â”€ processed/           # Chunk'lanmÄ±ÅŸ veriler
â”‚   â””â”€â”€ embeddings/          # KaydedilmiÅŸ embeddings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chunking.py          # Document chunking modÃ¼lÃ¼
â”‚   â”œâ”€â”€ embedding.py         # Embedding modÃ¼lÃ¼
â”‚   â”œâ”€â”€ indexing.py          # FAISS indexing
â”‚   â”œâ”€â”€ retrieval.py         # Retrieval modÃ¼lÃ¼
â”‚   â”œâ”€â”€ generation.py        # GPT-4o integration
â”‚   â””â”€â”€ evaluation.py        # Evaluation metrikleri
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ experiments.ipynb    # Deney notebooklarÄ±
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_rag.py          # Unit tests
â”œâ”€â”€ config.py                # KonfigÃ¼rasyon
â”œâ”€â”€ main.py                  # Ana uygulama
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§ Kontrol Listesi

- [ ] Dataset'i incele (cs-data/ klasÃ¶rÃ¼)
- [ ] Chunking stratejisi belirle (200-300 token Ã¶nerilen)
- [ ] Embedding model seÃ§ (all-MiniLM-L6-v2 baÅŸlangÄ±Ã§ iÃ§in)
- [ ] FAISS index oluÅŸtur
- [ ] Retrieval fonksiyonu implement et (top-k=5)
- [ ] GPT-4o prompt template hazÄ±rla
- [ ] Test sorularÄ± oluÅŸtur (20-30 soru)
- [ ] Recall@k hesapla
- [ ] RAG vs No-RAG karÅŸÄ±laÅŸtÄ±rmasÄ± yap
- [ ] Error analysis iÃ§in 3+ retrieval hatasÄ± bul
- [ ] Error analysis iÃ§in 3+ hallucination Ã¶rneÄŸi bul
- [ ] Rapor yaz (4-6 sayfa)

---

*Bu belge, IR Assignment 3 iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. Son gÃ¼ncelleme: Ocak 2026*
