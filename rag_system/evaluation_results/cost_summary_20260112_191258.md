## OpenAI Cost Summary (Estimated)

- **Generated at**: 2026-01-12T19:12:58.605795
- **Log file**: `/Users/alperendavran/Desktop/ir hw3/rag_system/evaluation_results/openai_cost_log.jsonl`

### Totals

- **Estimated total cost (USD)**: 0.027706
- **Total prompt tokens**: 133932
- **Total completion tokens**: 12694
- **Total events**: 159

### By model

| Model | Events | Prompt tokens | Completion tokens | Est. cost (USD) |
|---|---:|---:|---:|---:|
| `gpt-4o-mini` | 159 | 133932 | 12694 | 0.027706 |

### By operation

| Operation | Events | Est. cost (USD) |
|---|---:|---:|
| `llm_judge_faithfulness` | 78 | 0.015455 |
| `answer_generation` | 61 | 0.009720 |
| `llm_judge_compare_answers` | 20 | 0.002531 |

### Last 30 events

| ts_utc | operation | model | prompt | completion | cost_usd |
|---|---|---|---:|---:|---:|
| 2026-01-12T18:09:24.129881+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1140 | 61 | 0.00020759999999999998 |
| 2026-01-12T18:09:26.800356+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 860 | 51 | 0.00015959999999999998 |
| 2026-01-12T18:09:29.698877+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 300 | 102 | 0.00010619999999999999 |
| 2026-01-12T18:09:31.542973+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1172 | 52 | 0.00020700000000000002 |
| 2026-01-12T18:09:33.692497+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 866 | 64 | 0.00016829999999999997 |
| 2026-01-12T18:09:37.691625+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 340 | 133 | 0.0001308 |
| 2026-01-12T18:09:39.631534+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1164 | 52 | 0.00020580000000000002 |
| 2026-01-12T18:09:41.578463+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1004 | 52 | 0.00018179999999999997 |
| 2026-01-12T18:09:44.038713+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 576 | 90 | 0.0001404 |
| 2026-01-12T18:09:45.904684+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 912 | 50 | 0.0001668 |
| 2026-01-12T18:09:48.235711+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 918 | 44 | 0.00016409999999999998 |
| 2026-01-12T18:09:50.833005+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 429 | 92 | 0.00011955 |
| 2026-01-12T18:09:52.414450+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 856 | 56 | 0.000162 |
| 2026-01-12T18:09:55.069562+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1110 | 54 | 0.0001989 |
| 2026-01-12T18:09:57.551680+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 504 | 89 | 0.000129 |
| 2026-01-12T18:10:00.770798+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1454 | 80 | 0.0002661 |
| 2026-01-12T18:10:02.332814+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1185 | 47 | 0.00020595000000000002 |
| 2026-01-12T18:10:05.849834+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 395 | 101 | 0.00011984999999999999 |
| 2026-01-12T18:10:07.432832+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1252 | 60 | 0.00022380000000000002 |
| 2026-01-12T18:10:09.332713+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1477 | 68 | 0.00026235 |
| 2026-01-12T18:10:14.219227+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 735 | 107 | 0.00017444999999999998 |
| 2026-01-12T18:10:15.986904+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1071 | 60 | 0.00019664999999999998 |
| 2026-01-12T18:10:17.692195+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1047 | 46 | 0.00018465 |
| 2026-01-12T18:10:21.313114+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 343 | 90 | 0.00010545 |
| 2026-01-12T18:10:24.385152+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1445 | 77 | 0.00026295 |
| 2026-01-12T18:10:27.499327+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1250 | 53 | 0.00021930000000000002 |
| 2026-01-12T18:10:30.222736+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 303 | 85 | 9.645e-05 |
| 2026-01-12T18:10:34.563391+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 1252 | 57 | 0.000222 |
| 2026-01-12T18:10:38.719422+00:00 | `llm_judge_faithfulness` | `gpt-4o-mini` | 975 | 60 | 0.00018224999999999998 |
| 2026-01-12T18:10:44.148647+00:00 | `llm_judge_compare_answers` | `gpt-4o-mini` | 577 | 116 | 0.00015615 |